{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-06fffa32dec3>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('./MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):#打印10张图\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(X_train[i].reshape(28,28))\n",
    "    print(y_train[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建一个卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(784,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1c3b6c1898>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 3s 153us/step - loss: 0.0820\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.0595\n"
     ]
    }
   ],
   "source": [
    "history=m.fit(X_train,y_train,epochs=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),y_test.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img=X_train.reshape(X_train.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img=X_test.reshape(X_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 14s 692us/step - loss: 0.2690 - val_loss: 0.0974\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 14s 713us/step - loss: 0.0783 - val_loss: 0.0725\n"
     ]
    }
   ],
   "source": [
    "history=m.fit(X_train_img,y_train,epochs=2,batch_size=32,validation_data=(X_test_img, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m.predict(X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),y_test.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像的Normalize\n",
    "\n",
    "图像的Pixel->0-255->不适合作为X的输入\n",
    "\n",
    "目的：将图像进行归一化的缩放，使得Pixel变成标准化 (x-mean)/std\n",
    "\n",
    "思考：归一化后，真的不存在小于0/小于-1或者大于1的OutLier吗？不一定\n",
    "\n",
    "思考:归一化中的参数mean/std参考哪部分数据？A 训练集 B 评测集 C 训练集+评测集 ->A\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13070016"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3081593"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trains=transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3082,))#来自于训练集的mean和std\n",
    "])#data_trains同样可以适用于test数据集的归一化操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans_227=transforms.Compose([\n",
    "    transforms.Resize(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.MNIST('data',train=True,download=True,transform=data_trans_227)\n",
    "test_data=datasets.MNIST('data',train=False,download=True,transform=data_trans_227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000\n"
     ]
    }
   ],
   "source": [
    "print(n_train,n_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54000"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 目前完成了数据集的制作,下一步制作数据的iterator\n",
    "\n",
    "对于数据直接进行了minibatch等操作\n",
    "\n",
    "iterator提供了拿一个minibatch的接口，因此训练的时候通过dataiterator来控制step和输入训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #第一层卷积层，in_channel=1，output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        \n",
    "        self.fc1=nn.Linear(5*5*16,120)\n",
    "        \n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        \n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.conv1(x)\n",
    "        out=F.relu(out)\n",
    "        out=F.max_pool2d(out,2)\n",
    "        out=self.conv2(out)\n",
    "        out=F.relu(out)\n",
    "        out=F.max_pool2d(out,2)\n",
    "        out=out.view(out.shape[0],-1)\n",
    "        out=F.relu(self.fc1(out))\n",
    "        out=F.relu(self.fc2(out))\n",
    "        out=self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.conv_block=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(64,192,kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(192,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        )\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.fc_block=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,10),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out=self.conv_block(x)\n",
    "        out=self.avgpool(out)\n",
    "        out=out.view(out.size(0),256*6*6)\n",
    "        out=self.fc_block(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入模型与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='models'\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=LeNet().to(device)#构建了一个计算图模型并载入到了内存\n",
    "# model_path=os.path.join(model_dir,'lenet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AlexNet().to(device)#构建了一个计算图模型并载入到了内存\n",
    "model_path=os.path.join(model_dir,'alexnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv_block): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (fc_block): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunc=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx,y):\n",
    "    pred=fx.max(1,keepdim=True)[1]#argmax得到预测的类型\n",
    "    correct=pred.eq(y.view_as(pred)).sum()#得到正确答案的数量\n",
    "    acc=correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练和评测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,iterator,optimizer,lossfunc):#训练一个epoch\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.train()#将model的状态改成PHASE=Train\n",
    "    for (x,y) in iterator:#加载每一个minibatch\n",
    "        x=x.to(device)#将张量加入到设备中CPU/GPU\n",
    "        y=y.to(device)#将label加入到设备中CPU/GPU\n",
    "        optimizer.zero_grad()#将所有的神经元/参数的梯度“寄存器”都置零\n",
    "        fx=model(x)#对于输入的训练样本进行模型预测\n",
    "        loss=lossfunc(fx,y)#计算预测与label之间的差距\n",
    "        acc=accu(fx,y)#计算预测的准确率，用来做为显示\n",
    "        loss.backward()#通过Loss求得各个参数的梯度,求得的梯度存储在梯度“寄存器”中\n",
    "        optimizer.step()#对于参数进行统一的更新\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,device,iterator,lossfunc):#做一个评测集/验证集的完整评测并给出相应的分数\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()#将模型的状态修改成PHASE=Eval，这样不用去自动求导\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=lossfunc(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')#用来挑选最优模型的一个辅助变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    #对于全量的1个epoch的训练集数据进行梯度下降，并输出平均train_loss和train_acc\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,lossfunc)\n",
    "    #使用验证集对已经更新好参数的模型进行一轮验证，并输出平均的val_loss和val_acc\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,lossfunc)\n",
    "    if valid_loss<best_valid_loss:#代表该模型在验证集上是好于历史最好模型\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用测试集来测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.037584192861037646|Test Acc:0.9899482484076433\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loss,test_acc=evaluate(model,device,test_iterator,lossfunc)\n",
    "print('Test Loss:{0}|Test Acc:{1}'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
